OL_HUB_API_KEY=
OL_TOOL_LICENSE=
OL_ADMIN=openlegacy
OL_PASSWORD=olpassword

OLCODE_ADMIN=openlegacy
OLCODE_PASSWORD=olpassword

TERMIQ_DB_TYPE=POSTGRESQL
TERMIQ_DB_HOST=hub-postgres
TERMIQ_DB_PORT=5432
TERMIQ_DB_DATABASE=termiq
TERMIQ_DB_USERNAME=postgres
TERMIQ_DB_PASSWORD=olhubpassword

# ========================================
# Hub Configuration
# ========================================
OL_HUB_URL=http://localhost:8080
HUB_IAM_URL=http://localhost:9191
OL_ENT_AWS_METERING_OPTIONS=NONE

# ========================================
# AI Configuration
# ========================================
OL_AI_ENABLED_KEY=true
OL_AI_VENDOR=openai
OL_AI_MODEL_NAME=gpt-4.1
OL_AI_API_KEY=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
OL_AI_TEMPERATURE=0.1
OL_AI_DEBUG=false

# Optional: For custom LLM providers (Azure, custom endpoints, etc.)
OL_AI_BASE_URL=

# Optional: For Vertex AI
LLM_CONTEXT_ID=
LLM_TOKEN=
LLM_USERNAME=
LLM_PASSWORD=
LLM_LOCATION=

# Optional: LangChain Tracing (for debugging)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=

# ========================================
# Python AI Service Process Configuration
# ========================================
AI_PYTHON_EXEC_PATH=poetry
AI_APP_MODULE=app.main:app
AI_HOST=0.0.0.0
AI_PORT=8090
AI_WORKING_DIR=/usr/app/ai

# ========================================
# Python AI Service URL (Internal Communication)
# ========================================
PYTHON_AI_SERVICE_URL=http://127.0.0.1:8090

# ========================================
# Planner MCP Configuration
# ========================================
OL_PLANNER_MCP_URL=http://127.0.0.1:8080/planner/api/v1/mcp
OL_PLANNER_MAX_CONVERSATION_EXCHANGES=10
